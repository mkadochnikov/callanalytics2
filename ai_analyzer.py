#!/usr/bin/env python3
"""
–ö–ª–∞—Å—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ò–ò –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π
"""

from config import *
import pickle
from pathlib import Path
import numpy as np


class LocalAIAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤"""

    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        self._init_models()

        # –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π
        self.custom_objections_file = Path("bitrix_analytics/custom_objections.json")
        self.custom_objections = self._load_custom_objections()

    def _init_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ú–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–º
            self.classifier = pipeline(
                "zero-shot-classification",
                model="facebook/bart-large-mnli",
                device=0 if self.device == "cuda" else -1
            )
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            self.classifier = None

        try:
            # –ú–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π
            self.sentiment_model_name = "sismetanin/rubert-ru-sentiment-rureviews"
            self.sentiment_tokenizer = AutoTokenizer.from_pretrained(self.sentiment_model_name)
            self.sentiment_model = AutoModelForSequenceClassification.from_pretrained(self.sentiment_model_name)

            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            self.sentiment_model.to(self.device)
            self.sentiment_model.eval()

            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ sismetanin/rubert-ru-sentiment-rureviews –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å sentiment: {e}")
            self.sentiment_tokenizer = None
            self.sentiment_model = None

    def _load_custom_objections(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π"""
        try:
            if self.custom_objections_file.exists():
                with open(self.custom_objections_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π: {e}")
        return {}

    def _save_custom_objections(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π"""
        try:
            self.custom_objections_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.custom_objections_file, 'w', encoding='utf-8') as f:
                json.dump(self.custom_objections, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π: {e}")

    def analyze_sentiment(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é RuBERT –º–æ–¥–µ–ª–∏"""
        if not text.strip() or not self.sentiment_model or not self.sentiment_tokenizer:
            return {"sentiment": "neutral", "confidence": 0.0}

        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
            inputs = self.sentiment_tokenizer(
                text[:512],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=512
            )

            # –ü–µ—Ä–µ–Ω–æ—Å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = self.sentiment_model(**inputs)
                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)

            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            predicted_class = torch.argmax(predictions, dim=-1).item()
            confidence = torch.max(predictions).item()

            # –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏)
            sentiment_map = {0: "negative", 1: "neutral", 2: "positive"}
            sentiment = sentiment_map.get(predicted_class, "neutral")

            return {
                "sentiment": sentiment,
                "confidence": float(confidence)
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {e}")
            return {"sentiment": "neutral", "confidence": 0.0}

    def classify_topic(self, text: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º—ã —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
        if not text.strip():
            return "–û–±—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä"

        text_lower = text.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        topic_scores = {}
        for topic, keywords in CALL_TOPICS.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                topic_scores[topic] = score

        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        if topic_scores:
            best_topic = max(topic_scores, key=topic_scores.get)
            return best_topic

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ò–ò –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        if self.classifier:
            try:
                text_sample = text[:1000]
                result = self.classifier(text_sample, list(CALL_TOPICS.keys()))

                if result and 'labels' in result and len(result['labels']) > 0:
                    confidence = result['scores'][0]
                    if confidence > 0.2:
                        return result['labels'][0]
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ò–ò –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
        if len(text) < 50:
            return "–ö–æ—Ä–æ—Ç–∫–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä"
        elif any(word in text_lower for word in ["–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–ø—Ä–∏–≤–µ—Ç"]):
            return "–û–±—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä"
        else:
            return "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Ç–µ–º–∞"

    def find_objection_reason(self, text: str) -> Optional[Dict]:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π —Å —Å–∏—Å—Ç–µ–º–æ–π –¥–≤–æ–π–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        if not text.strip():
            return None

        text_lower = text.lower()

        # –≠—Ç–∞–ø 1: –ü–µ—Ä–≤–∏—á–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
        has_objection, objection_context = self._detect_objection_presence(text_lower)

        if not has_objection:
            return None

        # –≠—Ç–∞–ø 2: –ü–æ–∏—Å–∫ —Å—Ä–µ–¥–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        standard_objection = self._find_standard_objection(text_lower, objection_context)
        if standard_objection:
            return standard_objection

        # –≠—Ç–∞–ø 3: –ü–æ–∏—Å–∫ —Å—Ä–µ–¥–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        custom_objection = self._find_custom_objection(text_lower, objection_context)
        if custom_objection:
            return custom_objection

        # –≠—Ç–∞–ø 4: –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å –∂–µ—Å—Ç–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        new_objection = self._create_verified_objection(text, text_lower, objection_context)
        if new_objection:
            return new_objection

        # –≠—Ç–∞–ø 5: –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ - –ù–ï –∑–∞—è–≤–ª—è–µ–º –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ
        logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é")
        return None

    def _detect_objection_presence(self, text_lower: str) -> tuple[bool, str]:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç"""

        # –°–∏–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
        strong_indicators = [
            "–Ω–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ", "–Ω–µ –Ω—É–∂–Ω–æ", "–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç", "–Ω–µ —Ö–æ—á—É", "–Ω–µ –±—É–¥—É",
            "–æ—Ç–∫–∞–∂—É—Å—å", "–æ—Ç–∫–∞–∑—ã–≤–∞—é—Å—å", "–ø—Ä–æ—Ç–∏–≤", "–Ω–µ —Å–æ–≥–ª–∞—Å–µ–Ω", "–Ω–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç"
        ]

        # –°–ª–∞–±—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (—Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        weak_indicators = ["–Ω–µ—Ç", "–Ω–µ", "–æ—Ç–∫–∞–∑"]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        for indicator in strong_indicators:
            if indicator in text_lower:
                # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞
                pos = text_lower.find(indicator)
                context = text_lower[max(0, pos - 50):pos + 100]
                return True, context

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–∞–±—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        for indicator in weak_indicators:
            if indicator in text_lower:
                pos = text_lower.find(indicator)
                context = text_lower[max(0, pos - 50):pos + 100]

                # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã —Ä—è–¥–æ–º
                commercial_terms = [
                    "—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–¥–µ–Ω—å–≥–∏", "–±—é–¥–∂–µ—Ç", "–¥–æ—Ä–æ–≥–æ", "—É—Å–ª—É–≥–∞",
                    "–ø—Ä–æ–¥—É–∫—Ç", "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ", "–¥–æ–≥–æ–≤–æ—Ä", "–ø–æ–∫—É–ø–∫–∞", "–∑–∞–∫–∞–∑",
                    "–≤—Ä–µ–º—è", "—Å—Ä–æ–∫–∏", "—É—Å–ª–æ–≤–∏—è", "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è"
                ]

                if any(term in context for term in commercial_terms):
                    return True, context

        return False, ""

    def _find_standard_objection(self, text_lower: str, context: str) -> Optional[Dict]:
        """–ò—â–µ—Ç –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""

        objection_scores = {}

        for objection_name, objection_data in OBJECTION_CATEGORIES.items():
            score = 0
            keywords = objection_data["keywords"]

            for keyword in keywords:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –ø–æ–ª–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
                if keyword in text_lower:
                    score += 2

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
                if keyword in context:
                    score += 3

            if score >= 3:  # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                objection_scores[objection_name] = score

        if objection_scores:
            best_objection = max(objection_scores, key=objection_scores.get)
            recommendation = OBJECTION_CATEGORIES[best_objection]["recommendation"]

            return {
                "objection": best_objection,
                "recommendation": recommendation,
                "confidence": objection_scores[best_objection],
                "sentiment": {"sentiment": "negative", "confidence": 0.8}
            }

        return None

    def _find_custom_objection(self, text_lower: str, context: str) -> Optional[Dict]:
        """–ò—â–µ—Ç –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""

        objection_scores = {}

        for custom_name, custom_data in self.custom_objections.items():
            score = 0
            keywords = custom_data.get("keywords", [])

            for keyword in keywords:
                if keyword in text_lower:
                    score += 2
                if keyword in context:
                    score += 3

            if score >= 3:
                objection_scores[custom_name] = score

        if objection_scores:
            best_objection = max(objection_scores, key=objection_scores.get)
            recommendation = self.custom_objections[best_objection].get("recommendation", "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥")

            return {
                "objection": best_objection,
                "recommendation": recommendation,
                "confidence": objection_scores[best_objection],
                "sentiment": {"sentiment": "negative", "confidence": 0.8}
            }

        return None

    def _create_verified_objection(self, original_text: str, text_lower: str, context: str) -> Optional[Dict]:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è —Å –∂–µ—Å—Ç–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞"""

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é —Å—É—Ç—å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
        objection_essence = self._extract_verified_essence(text_lower, context)

        if not objection_essence:
            logger.info("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–µ—Ç–∫—É—é —Å—É—Ç—å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è")
            return None

        # –î–≤–æ–π–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏
        if not self._validate_objection_quality(objection_essence, original_text):
            logger.info(f"–í–æ–∑—Ä–∞–∂–µ–Ω–∏–µ '{objection_essence}' –Ω–µ –ø—Ä–æ—à–ª–æ –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞")
            return None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
        if self._is_duplicate_objection(objection_essence):
            logger.info(f"–í–æ–∑—Ä–∞–∂–µ–Ω–∏–µ '{objection_essence}' —è–≤–ª—è–µ—Ç—Å—è –¥—É–±–ª–∏–∫–∞—Ç–æ–º")
            return None

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        objection_name = f"üîç {objection_essence.capitalize()}"
        recommendation = self._generate_contextual_recommendation(objection_essence, context)

        self.custom_objections[objection_name] = {
            "keywords": [objection_essence.lower()],
            "recommendation": recommendation,
            "created_date": datetime.datetime.now().isoformat(),
            "source_context": context[:100],
            "validation_passed": True
        }

        self._save_custom_objections()
        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è: {objection_name}")

        return {
            "objection": objection_name,
            "recommendation": recommendation,
            "confidence": 3,
            "sentiment": {"sentiment": "negative", "confidence": 0.8},
            "is_new_category": True
        }

    def _extract_verified_essence(self, text_lower: str, context: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—É—é —Å—É—Ç—å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è"""

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–µ—Ç–∫–æ–π —Å—É—Ç–∏
        essence_patterns = [
            r'–Ω–µ\s+(–ø–æ–¥—Ö–æ–¥–∏—Ç|—É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç|–∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç|–Ω—É–∂–µ–Ω|–Ω—É–∂–Ω–æ|—Ç—Ä–µ–±—É–µ—Ç—Å—è)\s+(\w+(?:\s+\w+){0,2})',
            r'—Å–ª–∏—à–∫–æ–º\s+(–¥–æ—Ä–æ–≥–æ|–¥–æ—Ä–æ–≥–æ–π|–¥–æ—Ä–æ–≥–∏–µ|–≤—ã—Å–æ–∫–∞—è|–≤—ã—Å–æ–∫–∏–µ)\s*(\w+(?:\s+\w+){0,1})?',
            r'–Ω–µ—Ç\s+(–≤—Ä–µ–º–µ–Ω–∏|–¥–µ–Ω–µ–≥|–±—é–¥–∂–µ—Ç–∞|—Å—Ä–µ–¥—Å—Ç–≤|–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏|—Ä–µ—Å—É—Ä—Å–æ–≤)',
            r'—É–∂–µ\s+(–µ—Å—Ç—å|—Ä–∞–±–æ—Ç–∞–µ–º|–¥–æ–≥–æ–≤–æ—Ä–∏–ª–∏—Å—å|–∑–∞–∫–ª—é—á–∏–ª–∏)\s+(\w+(?:\s+\w+){0,2})',
            r'(\w+(?:\s+\w+){0,2})\s+–Ω–µ\s+(–ø–æ–¥—Ö–æ–¥–∏—Ç|—É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç)',
        ]

        for pattern in essence_patterns:
            matches = re.findall(pattern, context.lower())
            for match in matches:
                if isinstance(match, tuple):
                    essence_parts = [part.strip() for part in match if part.strip()]
                    essence = ' '.join(essence_parts)
                else:
                    essence = match.strip()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                if len(essence) >= 5 and len(essence.split()) >= 1:
                    return essence[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

        return None

    def _validate_objection_quality(self, essence: str, full_text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è"""

        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        checks = [
            len(essence) >= 5,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
            len(essence) <= 50,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
            not essence.isdigit(),  # –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä–∞–º–∏
            len(essence.split()) >= 1,  # –ú–∏–Ω–∏–º—É–º –æ–¥–Ω–æ —Å–ª–æ–≤–æ
            not all(c in '.,!?-()[]{}' for c in essence),  # –ù–µ —Ç–æ–ª—å–∫–æ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        ]

        # –î–æ–ª–∂–Ω—ã –ø—Ä–æ–π—Ç–∏ –≤—Å–µ –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        if not all(checks):
            return False

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Å—É—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–∞ —Å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        commercial_context_words = [
            '—Ü–µ–Ω–∞', '–¥–µ–Ω—å–≥–∏', '–¥–æ—Ä–æ–≥–æ', '–≤—Ä–µ–º—è', '—É—Å–ª—É–≥–∞', '–ø—Ä–æ–¥—É–∫—Ç',
            '—É—Å–ª–æ–≤–∏—è', '–¥–æ–≥–æ–≤–æ—Ä', '–±—é–¥–∂–µ—Ç', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è',
            '–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ', '—Ä–µ—à–µ–Ω–∏–µ', '–ø–æ–∫—É–ø–∫–∞', '–∑–∞–∫–∞–∑'
        ]

        essence_lower = essence.lower()
        full_text_lower = full_text.lower()

        # –õ–∏–±–æ –≤ —Å–∞–º–æ–π —Å—É—Ç–∏, –ª–∏–±–æ –≤ —Ç–µ–∫—Å—Ç–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
        has_commercial_context = (
                any(word in essence_lower for word in commercial_context_words) or
                any(word in full_text_lower for word in commercial_context_words)
        )

        return has_commercial_context

    def _is_duplicate_objection(self, essence: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö"""

        essence_lower = essence.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        for objection_name in OBJECTION_CATEGORIES.keys():
            objection_clean = objection_name.lower()
            if essence_lower in objection_clean or objection_clean in essence_lower:
                return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–µ–¥–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        for custom_name, custom_data in self.custom_objections.items():
            custom_clean = custom_name.lower()
            if essence_lower in custom_clean or custom_clean in essence_lower:
                return True

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            keywords = custom_data.get("keywords", [])
            for keyword in keywords:
                if essence_lower in keyword.lower() or keyword.lower() in essence_lower:
                    return True

        return False

    def _extract_meaningful_objection(self, text_lower: str, objection_indicators: List[str]) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None"""
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            sentences = re.split(r'[.!?]+', text_lower)

            # –ò—â–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏
            objection_sentences = []
            for sentence in sentences:
                sentence = sentence.strip()
                if (len(sentence) > 20 and len(sentence) < 150 and
                        any(indicator in sentence for indicator in objection_indicators)):
                    objection_sentences.append(sentence)

            if not objection_sentences:
                return None

            # –ë–µ—Ä–µ–º —Å–∞–º–æ–µ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            main_sentence = max(objection_sentences, key=len)

            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—É—é —Ñ—Ä–∞–∑—É –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
            objection_essence = self._extract_objection_essence(main_sentence)

            if not objection_essence or len(objection_essence) < 10:
                return None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            objection_name = f"üîç {objection_essence.capitalize()}"

            # –ù–µ —Å–æ–∑–¥–∞–µ–º, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∞—è
            existing_names = list(OBJECTION_CATEGORIES.keys()) + list(self.custom_objections.keys())
            if any(objection_essence.lower() in existing.lower() for existing in existing_names):
                return None

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            recommendation = self._generate_contextual_recommendation(objection_essence, main_sentence)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            self.custom_objections[objection_name] = {
                "keywords": [objection_essence.lower(), main_sentence[:50]],
                "recommendation": recommendation,
                "created_date": datetime.datetime.now().isoformat(),
                "source_sentence": main_sentence
            }

            self._save_custom_objections()
            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è: {objection_name}")

            return {
                "objection": objection_name,
                "recommendation": recommendation,
                "confidence": 2,
                "sentiment": {"sentiment": "negative", "confidence": 0.8},
                "is_new_category": True
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞—á–∏–º–æ–≥–æ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None

    def _extract_objection_essence(self, sentence: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É—Ç—å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"""

        # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        stop_words = {
            '–Ω–µ', '–Ω–µ—Ç', '–Ω–∞—Å', '—ç—Ç–æ', '—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–æ—á–µ–Ω—å', '—Ç–∞–∫',
            '—É–∂–µ', '–µ—â–µ', '—Ç–æ–ª—å–∫–æ', '–º–æ–∂–µ—Ç', '–º–æ–∂–Ω–æ', '–Ω—É–∂–Ω–æ', '–±—É–¥–µ—Ç', '–µ—Å—Ç—å',
            '—É', '–≤', '–Ω–∞', '—Å', '–æ—Ç', '–ø–æ', '–¥–ª—è', '–¥–æ', '–ø—Ä–∏', '–ø—Ä–æ', '–Ω–∞–¥', '–ø–æ–¥'
        }

        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –ø–æ—Å–ª–µ –æ—Ç—Ä–∏—Ü–∞–Ω–∏—è
        patterns = [
            r'–Ω–µ\s+(\w+(?:\s+\w+){0,2})',  # "–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç", "–Ω–µ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –Ω–∞—Å"
            r'–Ω–µ—Ç\s+(\w+(?:\s+\w+){0,2})',  # "–Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏", "–Ω–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏"
            r'—Å–ª–∏—à–∫–æ–º\s+(\w+)',  # "—Å–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–æ"
            r'(\w+)\s+–Ω–µ\s+–ø–æ–¥—Ö–æ–¥–∏—Ç',  # "—Ü–µ–Ω–∞ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç"
            r'(\w+)\s+–Ω–µ\s+—É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç',  # "—É—Å–ª–æ–≤–∏—è –Ω–µ —É—Å—Ç—Ä–∞–∏–≤–∞—é—Ç"
        ]

        for pattern in patterns:
            matches = re.findall(pattern, sentence)
            for match in matches:
                if isinstance(match, tuple):
                    match = ' '.join(match)

                # –û—á–∏—â–∞–µ–º –æ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤
                words = match.split()
                clean_words = [w for w in words if w not in stop_words and len(w) > 2]

                if clean_words and len(' '.join(clean_words)) > 5:
                    return ' '.join(clean_words)[:50]

        return ""

    def _generate_contextual_recommendation(self, essence: str, full_sentence: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è"""

        essence_lower = essence.lower()
        sentence_lower = full_sentence.lower()

        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if any(word in essence_lower for word in ["–≤—Ä–µ–º—è", "–Ω–µ–∫–æ–≥–¥–∞", "–∑–∞–Ω—è—Ç"]):
            return "–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å —É–¥–æ–±–Ω–æ–µ –≤—Ä–µ–º—è, —É—Å–∫–æ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è"
        elif any(word in essence_lower for word in ["–¥–æ—Ä–æ–≥–æ", "—Ü–µ–Ω–∞", "–¥–µ–Ω–µ–≥", "–±—é–¥–∂–µ—Ç"]):
            return "–û–±–æ—Å–Ω–æ–≤–∞—Ç—å —Ü–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ä–∞—Å—Å—Ä–æ—á–∫—É –∏–ª–∏ —Å–∫–∏–¥–∫—É"
        elif any(word in essence_lower for word in ["–Ω–µ –Ω—É–∂–Ω–æ", "–Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è", "–Ω–µ –∞–∫—Ç—É–∞–ª—å–Ω–æ"]):
            return "–í—ã—è–≤–∏—Ç—å —Å–∫—Ä—ã—Ç—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏, –ø–æ–∫–∞–∑–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã–≥–æ–¥—ã"
        elif any(word in essence_lower for word in ["–ø–æ–¥—É–º–∞—Ç—å", "—Ä–µ—à–µ–Ω–∏–µ", "–ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞—Ç—å—Å—è"]):
            return "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è, –Ω–∞–∑–Ω–∞—á–∏—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–π –∑–≤–æ–Ω–æ–∫"
        elif any(word in essence_lower for word in ["—É—Å–ª–æ–≤–∏—è", "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è", "–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç"]):
            return "–í—ã—è—Å–Ω–∏—Ç—å –∂–µ–ª–∞–µ–º—ã–µ —É—Å–ª–æ–≤–∏—è, –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã"
        else:
            return f"–ü—Ä–æ—Ä–∞–±–æ—Ç–∞—Ç—å –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ '{essence}', –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ"

    def _create_new_objection_category(self, text_lower: str, sentiment_result: Dict) -> Optional[Dict]:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ —Å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
            sentences = re.split(r'[.!?]+', text_lower)
            objection_phrases = []

            # –ò—â–µ–º —Ñ—Ä–∞–∑—ã —Å –æ—Ç–∫–∞–∑–æ–º –∏ –∏—Ö –ø—Ä–∏—á–∏–Ω—ã
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) > 15 and any(word in sentence for word in ["–Ω–µ", "–Ω–µ—Ç", "–æ—Ç–∫–∞–∑", "–ø—Ä–æ—Ç–∏–≤"]):
                    # –û—á–∏—â–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∑–Ω–∞—á–∏–º—ã–µ —Ñ—Ä–∞–∑—ã
                    cleaned = re.sub(r'\b(–∏|–∏–ª–∏|–Ω–æ|–∞|–≤|–Ω–∞|—Å|–æ—Ç|–ø–æ|–¥–ª—è|–¥–æ|–ø—Ä–∏|–ø—Ä–æ|–Ω–∞–¥|–ø–æ–¥|—ç—Ç–æ|—ç—Ç–æ|—á—Ç–æ|–∫–∞–∫|–≥–¥–µ|–∫–æ–≥–¥–∞)\b',
                                     '', sentence)
                    cleaned = re.sub(r'\s+', ' ', cleaned).strip()

                    if len(cleaned) > 10:
                        objection_phrases.append(cleaned)

            if not objection_phrases:
                return None

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ø—Ä–∏—á–∏–Ω—É –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
            main_objection_text = objection_phrases[0][:80] if objection_phrases else "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ"

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
            category_name = self._generate_meaningful_objection_name(main_objection_text, text_lower)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            if category_name in self.custom_objections or category_name in OBJECTION_CATEGORIES:
                return None  # –ù–µ —Å–æ–∑–¥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
            recommendation = self._generate_objection_recommendation(main_objection_text)

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            self.custom_objections[category_name] = {
                "keywords": objection_phrases[:3],  # –ë–µ—Ä–µ–º –¥–æ 3 –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
                "recommendation": recommendation,
                "created_date": datetime.datetime.now().isoformat(),
                "sample_text": main_objection_text,
                "main_phrase": main_objection_text
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            self._save_custom_objections()

            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è: {category_name}")

            return {
                "objection": category_name,
                "recommendation": recommendation,
                "confidence": 2,
                "sentiment": sentiment_result,
                "is_new_category": True
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return None

    def _generate_meaningful_objection_name(self, main_text: str, full_text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è"""

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è
        objection_patterns = {
            "–ü—Ä–æ–±–ª–µ–º—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç–æ–º": ["–¥–æ–∫—É–º–µ–Ω—Ç—ã", "–±—É–º–∞–≥–∏", "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ", "–¥–æ–≥–æ–≤–æ—Ä", "–±—é—Ä–æ–∫—Ä–∞—Ç–∏—è"],
            "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏": ["–Ω–µ –∑–Ω–∞—é", "–Ω–µ –ø–æ–Ω–∏–º–∞—é", "–Ω–µ–ø–æ–Ω—è—Ç–Ω–æ", "–Ω—É–∂–Ω–æ —É–∑–Ω–∞—Ç—å", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–∞–ª–æ"],
            "–ü—Ä–æ–±–ª–µ–º—ã —Å –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ–º": ["–≤–Ω–µ–¥—Ä–µ–Ω–∏–µ", "—É—Å—Ç–∞–Ω–æ–≤–∫–∞", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞", "—Å–ª–æ–∂–Ω–æ –≤–Ω–µ–¥—Ä–∏—Ç—å", "–¥–æ–ª–≥–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å"],
            "–ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤": ["–Ω–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤", "–Ω–µ—Ç –ª—é–¥–µ–π", "–Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ", "–Ω–µ–∫–æ–º—É –∑–∞–Ω–∏–º–∞—Ç—å—Å—è"],
            "–ü–ª–∞–Ω—ã —É–∂–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –ø–µ—Ä–∏–æ–¥": ["—Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥", "–ø–æ–∑–∂–µ", "–≤ –ø–ª–∞–Ω–∞—Ö", "–±—é–¥–∂–µ—Ç —Å–ª–µ–¥—É—é—â–µ–≥–æ –≥–æ–¥–∞"],
            "–ù—É–∂–Ω–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ —Å –¥—Ä—É–≥–∏–º–∏": ["—Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å", "–æ–±—Å—É–¥–∏—Ç—å —Å –∫–æ–º–∞–Ω–¥–æ–π", "—Ä–µ—à–µ–Ω–∏–µ –Ω–µ –º–æ–µ", "–Ω—É–∂–Ω–æ –æ–¥–æ–±—Ä–µ–Ω–∏–µ"],
            "–°–æ–º–Ω–µ–Ω–∏—è –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ": ["–Ω–µ —É–≤–µ—Ä–µ–Ω", "—Å–æ–º–Ω–µ–≤–∞—é—Å—å", "–∞ –≤–¥—Ä—É–≥ –Ω–µ –ø–æ–º–æ–∂–µ—Ç", "–Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç"],
            "–¢–µ–∫—É—â–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã": ["–¥—Ä—É–≥–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã", "—Å–µ–π—á–∞—Å –Ω–µ –¥–æ —ç—Ç–æ–≥–æ", "–µ—Å—Ç—å –±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏"]
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –ø–æ–¥ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for objection_name, keywords in objection_patterns.items():
            if any(keyword in full_text.lower() for keyword in keywords):
                return f"üìù {objection_name}"

        # –ï—Å–ª–∏ –Ω–µ –ø–æ–¥–æ—à–ª–æ –Ω–∏ –ø–æ–¥ –æ–¥–∏–Ω –ø–∞—Ç—Ç–µ—Ä–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        words = main_text.lower().split()
        key_words = []

        # –û—Ç–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–∏–º—ã–µ —Å–ª–æ–≤–∞
        skip_words = {
            '–Ω–µ', '–Ω–µ—Ç', '–Ω–∞—Å', '—ç—Ç–æ', '—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–æ—á–µ–Ω—å', '—Ç–∞–∫',
            '—É–∂–µ', '–µ—â–µ', '—Ç–æ–ª—å–∫–æ', '–º–æ–∂–µ—Ç', '–º–æ–∂–Ω–æ', '–Ω—É–∂–Ω–æ', '–±—É–¥–µ—Ç', '–µ—Å—Ç—å'
        }

        for word in words:
            if len(word) > 3 and word not in skip_words:
                key_words.append(word)
                if len(key_words) >= 3:
                    break

        if key_words:
            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
            key_phrase = ' '.join(key_words[:2])
            return f"‚ùì –í–æ–∑—Ä–∞–∂–µ–Ω–∏–µ: {key_phrase}"

        return f"‚ùì –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ"

    def _generate_objection_recommendation(self, objection_text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è"""

        text_lower = objection_text.lower()

        if any(word in text_lower for word in ["–¥–æ–∫—É–º–µ–Ω—Ç—ã", "–±—É–º–∞–≥–∏", "–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ"]):
            return "–£–ø—Ä–æ—Å—Ç–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–æ–±–æ—Ä–æ—Ç, –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø–æ–º–æ—â—å –≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–∏"
        elif any(word in text_lower for word in ["–Ω–µ –∑–Ω–∞—é", "–Ω–µ –ø–æ–Ω–∏–º–∞—é", "–Ω–µ–ø–æ–Ω—è—Ç–Ω–æ"]):
            return "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é"
        elif any(word in text_lower for word in ["–≤–Ω–µ–¥—Ä–µ–Ω–∏–µ", "—É—Å—Ç–∞–Ω–æ–≤–∫–∞", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞"]):
            return "–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø—Ä–∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏, –æ–±—É—á–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã"
        elif any(word in text_lower for word in ["–Ω–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤", "–Ω–µ—Ç –ª—é–¥–µ–π", "–Ω–µ–∫–æ–º—É"]):
            return "–ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å –≤—ã–¥–µ–ª–µ–Ω–Ω—É—é –∫–æ–º–∞–Ω–¥—É –∏–ª–∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–æ–Ω–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É"
        elif any(word in text_lower for word in ["—Å–ª–µ–¥—É—é—â–∏–π", "–ø–æ–∑–∂–µ", "–ø–ª–∞–Ω–∞—Ö"]):
            return "–ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞—Ç—å –º–µ—Å—Ç–æ –≤ –ø–ª–∞–Ω–∞—Ö, –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –ø–∏–ª–æ—Ç–Ω—ã–π –ø—Ä–æ–µ–∫—Ç"
        elif any(word in text_lower for word in ["—Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å", "–æ–±—Å—É–¥–∏—Ç—å", "–æ–¥–æ–±—Ä–µ–Ω–∏–µ"]):
            return "–ü–æ–º–æ—á—å —Å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–µ–π –¥–ª—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –º–∞—Ç–µ—Ä–∏–∞–ª—ã"
        elif any(word in text_lower for word in ["–Ω–µ —É–≤–µ—Ä–µ–Ω", "—Å–æ–º–Ω–µ–≤–∞—é—Å—å", "–Ω–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω"]):
            return "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∫–µ–π—Å—ã, –≥–∞—Ä–∞–Ω—Ç–∏–∏, –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
        else:
            return "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –¥–µ—Ç–∞–ª—å–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π"

    def get_all_objection_categories(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ + –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ)"""
        all_categories = OBJECTION_CATEGORIES.copy()
        all_categories.update(self.custom_objections)
        return all_categories

    def extract_key_points(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text.strip():
            return []

        sentences = re.split(r'[.!?]+', text)

        key_sentences = []
        important_words = [
            '–≤–∞–∂–Ω–æ', '–≥–ª–∞–≤–Ω–æ–µ', '–æ—Å–Ω–æ–≤–Ω–æ–µ', '–Ω—É–∂–Ω–æ', '—Ç—Ä–µ–±—É–µ—Ç—Å—è', '–ø—Ä–æ–±–ª–µ–º–∞',
            '–≤–æ–ø—Ä–æ—Å', '—Ä–µ—à–µ–Ω–∏–µ', '–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—É—Å–ª–æ–≤–∏—è',
            '–¥–æ–≥–æ–≤–æ—Ä', '–∑–∞–∫–∞–∑', '—É—Å–ª—É–≥–∞', '–ø—Ä–æ–¥—É–∫—Ç', '–∫–ª–∏–µ–Ω—Ç', '–∫–æ–º–ø–∞–Ω–∏—è',
            '–≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ', '–Ω–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç', '–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç', '–±–µ—Å–ø–æ–∫–æ–∏—Ç'
        ]

        for sentence in sentences[:10]:
            sentence = sentence.strip()
            if len(sentence) > 20 and len(sentence) < 200:
                sentence_lower = sentence.lower()
                if any(word in sentence_lower for word in important_words):
                    key_sentences.append(sentence)

        return key_sentences[:3]

    # –ú–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    def find_rejection_reason(self, text: str) -> Optional[str]:
        """–£—Å—Ç–∞—Ä–µ–≤—à–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ find_objection_reason()"""
        logger.warning("–ú–µ—Ç–æ–¥ find_rejection_reason —É—Å—Ç–∞—Ä–µ–ª. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ find_objection_reason()")

        objection_result = self.find_objection_reason(text)
        if objection_result:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            return objection_result["objection"]
        return None